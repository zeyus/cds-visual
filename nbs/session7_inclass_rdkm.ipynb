{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 7 - Neural Networks for image data\n",
    "\n",
    "In this notebook, we're going to see how we can train simple neural networks using ```TensorFlow```, a machine learning and deep learning framework developed by Google Research. You can find the documentation [here](https://www.tensorflow.org/).\n",
    "\n",
    "We're still working on greyscale images at this point - next week, we'll start thinking about working with full colour images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic tools\n",
    "import numpy as np\n",
    "\n",
    "# tools from sklearn\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# tools from tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data, train-test split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to download the ```MNIST``` dataset again, so that we compare this pipeline to the baseline benchmarks we created previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "\n",
    "# normalise data\n",
    "data = data.astype(\"float\")/255.0\n",
    "\n",
    "# split data\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(data,\n",
    "                                                    labels, \n",
    "                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert labels to one-hot encoding\n",
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(y_train)\n",
    "y_test = lb.fit_transform(y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define neural network architecture using ```tf.keras```\n",
    "\n",
    "We're now going to create our neural network using ```TensorFlow```. In particular, we're going to using the ```keras``` wrapper which makes the syntax a bit simpler to work with.\n",
    "\n",
    "The code below makes a fully-connected, feed-forward neural network with the following features:\n",
    "\n",
    "- Input layer of 784\n",
    "- One hidden layer of 256\n",
    "- Second hidden layer of 128\n",
    "- An output layer of 10 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define architecture 784x256x128x10\n",
    "model = Sequential()\n",
    "model.add(Dense(256, \n",
    "                input_shape=(784,), \n",
    "                activation=\"relu\"))\n",
    "model.add(Dense(128, \n",
    "                activation=\"relu\"))\n",
    "model.add(Dense(10, \n",
    "                activation=\"softmax\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show summary of model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise model layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to do view this, there are some extra things that you can install - ```TensorFlow``` gives you instructions to do that.\n",
    "\n",
    "**NB:** This might not work on Windows (but I'm not sure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile model loss function, optimizer, and preferred metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the big differences with ```TensorFlow``` vs ```scikit-learn``` is that we have much more control over how the optimization algorithm works.\n",
    "\n",
    "We initalize the optimizer and then we have to *compile* the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model using SGD\n",
    "sgd = SGD(0.01)\n",
    "model.compile(loss=\"categorical_crossentropy\", \n",
    "              optimizer=sgd, \n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model and save history"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've done that, it's just a case of fitting the model to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=10, \n",
    "                    batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise using ```matplotlib```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"fivethirtyeight\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, 10), history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, 10), history.history[\"val_loss\"], label=\"val_loss\", linestyle=\":\")\n",
    "plt.plot(np.arange(0, 10), history.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, 10), history.history[\"val_accuracy\"], label=\"val_acc\", linestyle=\":\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to do a little bit of extra work to get the classification report to work properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(X_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test.argmax(axis=1), \n",
    "                            predictions.argmax(axis=1), \n",
    "                            target_names=[str(x) for x in lb.classes_]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task\n",
    "\n",
    "1. Turn the above into a ```.py``` script which can be run from the command line. Use argparse if you think it's relevant!\n",
    "2. Use this notebook as a template to train a neural network on the ```Cifar-10``` dataset instead of ```MNIST```.\n",
    "3. Turn *that* notebook into a ```.py``` script, too"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
